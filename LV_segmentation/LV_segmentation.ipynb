{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LV_segmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eZe8vekln9j6","colab_type":"text"},"source":["# Neural network for segmenting LV of heart\n","\n","## Introduction\n","This work was performed as part of the MRAI workshop (MIDL 2019 satellite meeting) with exercises designed by Esther Puyol (https://github.com/estherpuyol/MRAI_workshop).\n","\n","### Objective\n","Train a simple neural network to automatically segment the Left ventricle from 2D short axis cardiac MR images."]},{"cell_type":"markdown","metadata":{"id":"MQirRpaep-kM","colab_type":"text"},"source":["## Import modules\n","The network is built using functions and classes from the [pytorch library](https://pytorch.org/docs/stable/index.html) "]},{"cell_type":"code","metadata":{"id":"og-H1NZBqaFE","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import pylab as plt#\n","import tensorflow as tf\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn.model_selection import StratifiedShuffleSplit"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P-2sznKCpSGC","colab_type":"text"},"source":["## Download dataset\n","The data for this study is from the [Sunnybrook Cardiac Data](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/)\n","\n","A preprocessed subset of this data is used, where the data is filtered to contain only left ventricle myocardium segmentations and reduced in XY dimensions."]},{"cell_type":"code","metadata":{"id":"-B0W1zJKpPdk","colab_type":"code","colab":{}},"source":["![ -f scd_lvsegs.npz ] || wget https://github.com/estherpuyol/MRAI_workshop/raw/master/scd_lvsegs.npz\n","\n","data = np.load('scd_lvsegs.npz') # load all the data from the archive\n","\n","images = data['images'] # images in BHW array order : .shape (420, 64, 64)]\n","segs = data['segs'] # segmentations in BHW array order : .shape (420, 64, 64)\n","caseIndices = data['caseIndices'] # the indices in `images` for each case : .shape (45, 2)\n","\n","images = images.astype(np.float32)/images.max() # normalize images"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A2mh117Tqibl","colab_type":"text"},"source":["## Split training and test data\n","This code block splits the data set into training and test data where the variable n_training determines the number of test cases.  "]},{"cell_type":"code","metadata":{"id":"0jQ8Ti5ZspKA","colab_type":"code","colab":{}},"source":["n_training = 6\n","\n","testIndex = caseIndices[-n_training,0] # keep the last n_training cases for testing\n","\n","# divide the images, segmentations, and categories into train/test sets\n","trainImages,trainSegs = images[:testIndex],segs[:testIndex]\n","testImages,testSegs = images[testIndex:],segs[testIndex:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1uDuNzItFQx","colab_type":"text"},"source":["## Define segmentation network\n","Here two classes are defined: \n","\n","The first describes the loss function ```DiceLoss``` which will provide a measure of overlap between ground truth segmentations and the network outputs. \n","\n","The second class ```SegNet``` is our artifical neural network that inherits methods from the base NN class torch.nn.Module. \n"]},{"cell_type":"code","metadata":{"id":"yoqHiPFytdg9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e5750c38-998e-44af-c05d-ab3d736bcda0","executionInfo":{"status":"ok","timestamp":1565021645133,"user_tz":-60,"elapsed":407,"user":{"displayName":"Laurence Jackson","photoUrl":"https://lh4.googleusercontent.com/-7DuU4tbtAgI/AAAAAAAAAAI/AAAAAAAABA0/VkmK1bbpYbQ/s64/photo.jpg","userId":"10906345623450179926"}}},"source":["class DiceLoss(tf.keras.losses.Loss):\n","    '''This defines the binary dice loss function used to assess segmentation overlap.'''\n","    def call(self, y_true, y_pred):\n","        smooth=1e-5\n","        batchsize = target.size(0)\n","        source = source.sigmoid() # apply sigmoid to the source logits to impose it onto the [0,1] interval\n","        \n","        # flatten target and source arrays to 2D BV arrays\n","        tsum = target.view(batchsize, -1) \n","        psum = source.view(batchsize, -1)\n","        \n","        intersection=psum*tsum\n","        sums = psum+tsum \n","\n","        # compute the score, the `smooth` value is used to smooth results and prevent divide-by-zero\n","        score = 2.0 * (intersection.sum(1) + smooth) / (sums.sum(1) + smooth)\n","        \n","        # `score` is 1 for perfectly identical source and target, 0 for entirely disjoint\n","        return 1 - score.sum() / batchsize\n","\n","\n","\n","class unet_block(tf.keras.Model):\n","\n","    def __init__(self, Cin, Cout, subblock):\n","        \"\"\"initialise unit\"\"\"\n","        super().__init__()\n","        self._encode = tf.keras.layers.Conv2D(Cout, (3,3), strides=(2,2), padding='valid')\n","        self._encode_norm = tf.keras.layers.BatchNormalization(Cout)\n","        self._encode_dropout = tf.keras.layers.Dropout(rate=0.2)\n","        self._encode_activation = tf.keras.layers.Activation(tf.nn.leaky_relu)\n","\n","        self._subblock = subblock\n","\n","        self._decode = tf.keras.layers.Conv2DTranspose(Cin, (3,3), stride=(2,2), padding='valid')\n","        self._decode_norm = tf.keras.layers.BatchNormalization(Cin)\n","        self._decode_dropout = tf.keras.layers.Dropout(rate=0.2)\n","        self._decode_activation = tf.keras.layers.Activation(tf.nn.leaky_relu)\n","\n","    def call(self, tensor_in, training=False):\n","        \"\"\"Forward pass - encode block -> subblocks -> decode block\"\"\"\n","        enc = self._encode(tensor_in)\n","        enc = self._encode_norm(enc)\n","        if training:\n","            enc = self._encode_dropout(enc)\n","        enc = self._encode_activation(enc)\n","\n","        sub = self._subblock(enc)\n","        sub = tf.concat([enc,sub], axis=1)\n","\n","        dec = self._decode(sub)\n","        dec = self._decode_norm(dec)\n","        if training:\n","            dec = self._decode_dropout(dec)\n","        dec = self._decode_activation(dec)\n","\n","        return dec\n","\n","\n","class Unet(tf.keras.Model):\n","    \"\"\"Builds unet\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        filters_bottom = 64\n","\n","        # bottom subblock\n","        net = tf.keras.Sequential()\n","        net.add(tf.keras.layers.Conv2D(filters_bottom, (3,3), strides=2, padding='valid'))\n","        net.add(tf.keras.layers.BatchNormalization(filters_bottom))\n","        net.add(tf.keras.layers.Activation(tf.nn.leaky_relu))\n","\n","        # build the unet structure from the bottom up\n","        net=UnetBlock(32,filters_bottom,net)\n","        net=UnetBlock(16,32,net)\n","        net=UnetBlock(8,16,net)\n","        net=UnetBlock(4,8,net)\n","\n","        # final top-level structure omits dropout and applies sigmoid to the output\n","        self.model =  tf.keras.Sequential(\n","                                          nn.Conv2d(1,4,3,1,1),\n","                                          nn.InstanceNorm2d(4),\n","                                          nn.PReLU(),\n","                                          net,\n","                                          nn.Conv2d(4,1,3,1,1),\n","                                          )\n","\n","    def call(self, x):\n","        return self.model(x)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f86752f1ef0>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YOfRqQ4Kt7MF","colab_type":"text"},"source":["## Train network"]},{"cell_type":"code","metadata":{"id":"Rw0dMKb-t_FJ","colab_type":"code","outputId":"1805de29-ce4b-429e-cf53-f1fe65b3137e","executionInfo":{"status":"error","timestamp":1565021467304,"user_tz":-60,"elapsed":513,"user":{"displayName":"Laurence Jackson","photoUrl":"https://lh4.googleusercontent.com/-7DuU4tbtAgI/AAAAAAAAAAI/AAAAAAAABA0/VkmK1bbpYbQ/s64/photo.jpg","userId":"10906345623450179926"}},"colab":{"base_uri":"https://localhost:8080/","height":325}},"source":["# store the training data as tensors\n","trainTensor = tf.convert_to_tensor(trainImages[:,None])\n","segTensor = tf.convert_to_tensor(trainSegs[:,None].astype(np.float32))\n","\n","# create network object\n","net = Unet()\n","\n","# choose a device and  (remember to set Google Colab environment runtime to use GPU)\n","#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","tf.device(\"/device:GPU:0\")\n","\n","\n","# move the net and tensors to device memory\n","#net = net.to(device)\n","#trainTensor = trainTensor.to(device)\n","#segTensor = segTensor.to(device)\n","\n","# define optimizer and loss function\n","opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n","loss=DiceLoss()\n","\n","trainSteps = 5000\n","losses = []\n","\n","# run through training steps\n","for t in range(1,trainSteps+1):\n","    opt.zero_grad()\n","    pred = net(trainTensor)\n","    if t == 1:\n","      print('pred shape: ' + str(pred.size()))\n","      print('segTensor shape: ' + str(segTensor.size()))\n","    lossval = loss(pred,segTensor)\n","    lossval.backward()\n","    opt.step()\n","        \n","    losses.append(lossval.item())\n","    if t%(trainSteps//20) == 0:\n","        print(t,lossval.item())    \n","\n","# result\n","sample = np.random.randint(0, pred.shape[0]-1 )  # choose random sample to visualise segmentation the network predicted for it\n","print('Showing results from random sample: %d' % sample)\n","pred.shape\n","predSample=pred[sample,0].cpu().data.numpy()\n","fig,ax=plt.subplots(1,5,figsize=(20,5))\n","ax[0].set_title('Loss')\n","ax[0].semilogy(losses)\n","ax[1].set_title('Sample Image')\n","ax[1].imshow(trainImages[10])\n","ax[2].set_title('Sample Ground Truth')\n","ax[2].imshow(trainSegs[10])\n","ax[3].set_title('Sample Logits')\n","ax[3].imshow(predSample)\n","ax[4].set_title('Sample Predicted Segmentation')\n","ax[4].imshow(predSample>0.5)"],"execution_count":55,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-7fcae76c8af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-51-7ac1d00329f9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters_bottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters_bottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                                   )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() takes from 1 to 3 positional arguments but 4 were given"]}]}]}