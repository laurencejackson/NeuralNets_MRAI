{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LV_segmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eZe8vekln9j6","colab_type":"text"},"source":["# Neural network for segmenting LV of heart\n","\n","## Introduction\n","This work was performed as part of the MRAI workshop (MIDL 2019 satellite meeting) with exercises designed by Esther Puyol (https://github.com/estherpuyol/MRAI_workshop).\n","\n","### Objective\n","Train a simple neural network to automatically segment the Left ventricle from 2D short axis cardiac MR images."]},{"cell_type":"markdown","metadata":{"id":"MQirRpaep-kM","colab_type":"text"},"source":["## Import modules\n","The network is built using functions and classes from the [pytorch library](https://pytorch.org/docs/stable/index.html) "]},{"cell_type":"code","metadata":{"id":"og-H1NZBqaFE","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import pylab as plt#\n","import torch, torch.nn as nn, torch.nn.functional as F\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn.model_selection import StratifiedShuffleSplit"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P-2sznKCpSGC","colab_type":"text"},"source":["## Download dataset\n","The data for this study is from the [Sunnybrook Cardiac Data](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/)\n","\n","A preprocessed subset of this data is used, where the data is filtered to contain only left ventricle myocardium segmentations and reduced in XY dimensions."]},{"cell_type":"code","metadata":{"id":"-B0W1zJKpPdk","colab_type":"code","outputId":"6a218e91-023b-4c6a-c4bf-605df338f840","executionInfo":{"status":"ok","timestamp":1564839810037,"user_tz":-60,"elapsed":2263,"user":{"displayName":"Laurence Jackson","photoUrl":"https://lh4.googleusercontent.com/-7DuU4tbtAgI/AAAAAAAAAAI/AAAAAAAABA0/VkmK1bbpYbQ/s64/photo.jpg","userId":"10906345623450179926"}},"colab":{"base_uri":"https://localhost:8080/","height":311}},"source":["![ -f scd_lvsegs.npz ] || wget https://github.com/estherpuyol/MRAI_workshop/raw/master/scd_lvsegs.npz\n","\n","data = np.load('scd_lvsegs.npz') # load all the data from the archive\n","\n","images = data['images'] # images in BHW array order : .shape (420, 64, 64)]\n","segs = data['segs'] # segmentations in BHW array order : .shape (420, 64, 64)\n","caseIndices = data['caseIndices'] # the indices in `images` for each case : .shape (45, 2)\n","\n","images = images.astype(np.float32)/images.max() # normalize images"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2019-08-03 13:43:28--  https://github.com/estherpuyol/MRAI_workshop/raw/master/scd_lvsegs.npz\n","Resolving github.com (github.com)... 192.30.253.113\n","Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/estherpuyol/MRAI_workshop/master/scd_lvsegs.npz [following]\n","--2019-08-03 13:43:28--  https://raw.githubusercontent.com/estherpuyol/MRAI_workshop/master/scd_lvsegs.npz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2133403 (2.0M) [application/octet-stream]\n","Saving to: ‘scd_lvsegs.npz’\n","\n","scd_lvsegs.npz      100%[===================>]   2.03M  --.-KB/s    in 0.05s   \n","\n","2019-08-03 13:43:29 (38.6 MB/s) - ‘scd_lvsegs.npz’ saved [2133403/2133403]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A2mh117Tqibl","colab_type":"text"},"source":["## Split training and test data\n","This code block splits the data set into training and test data where the variable n_training determines the number of test cases.  "]},{"cell_type":"code","metadata":{"id":"0jQ8Ti5ZspKA","colab_type":"code","colab":{}},"source":["n_training = 6\n","\n","testIndex = caseIndices[-n_training,0] # keep the last n_training cases for testing\n","\n","# divide the images, segmentations, and categories into train/test sets\n","trainImages,trainSegs = images[:testIndex],segs[:testIndex]\n","testImages,testSegs = images[testIndex:],segs[testIndex:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1uDuNzItFQx","colab_type":"text"},"source":["## Define segmentation network\n","Here two classes are defined: \n","\n","The first describes the loss function ```DiceLoss``` which will provide a measure of overlap between ground truth segmentations and the network outputs. \n","\n","The second class ```SegNet``` is our artifical neural network that inherits methods from the base NN class torch.nn.Module. \n","\n","This auto-encoder has 4 layers..."]},{"cell_type":"code","metadata":{"id":"yoqHiPFytdg9","colab_type":"code","colab":{}},"source":["class DiceLoss(nn.modules.loss._Loss):\n","    '''This defines the binary dice loss function used to assess segmentation overlap.'''\n","    def forward(self, source, target, smooth=1e-5):\n","        batchsize = target.size(0)\n","        source = source.sigmoid() # apply sigmoid to the source logits to impose it onto the [0,1] interval\n","        \n","        # flatten target and source arrays to 2D BV arrays\n","        tsum = target.view(batchsize, -1) \n","        psum = source.view(batchsize, -1)\n","        \n","        intersection=psum*tsum\n","        sums = psum+tsum \n","\n","        # compute the score, the `smooth` value is used to smooth results and prevent divide-by-zero\n","        score = 2.0 * (intersection.sum(1) + smooth) / (sums.sum(1) + smooth)\n","        \n","        # `score` is 1 for perfectly identical source and target, 0 for entirely disjoint\n","        return 1 - score.sum() / batchsize\n","\n","# Segmentation network\n","class SegNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.model=nn.Sequential(\n","            # layer 1: convolution, normalization, downsampling\n","            nn.Conv2d(1,3,3,1,1),\n","            nn.BatchNorm2d(3),\n","            nn.PReLU(),\n","            nn.MaxPool2d(3,1,1), # 64\n","            # layer 2: convolution, normalization, downsampling\n","            nn.Conv2d(3,5,5,1,2),\n","            nn.BatchNorm2d(5),\n","            nn.PReLU(),\n","            nn.MaxPool2d(5,2,2), # 32\n","            # layer 3\n","            nn.Conv2d(5,7,3,1,1),\n","            nn.BatchNorm2d(7),\n","            nn.PReLU(),\n","            nn.MaxPool2d(3,2,1), # 16\n","            # bottom layer\n","            nn.Conv2d(7,7,3,1,1),\n","            nn.BatchNorm2d(7),\n","            nn.PReLU(),\n","            nn.MaxPool2d(3,1,1), # 16\n","            # layer 4\n","            nn.ConvTranspose2d(7,5,3,2,1,1),\n","            nn.BatchNorm2d(5),\n","            nn.PReLU(), # 32\n","            # layer 5\n","            nn.ConvTranspose2d(5,3,5,2,2,1),\n","            nn.BatchNorm2d(3),\n","            nn.PReLU(),# 64\n","            # layer 6: output\n","            nn.Conv2d(3,1,3,1,1),\n","        )\n","        \n","    def forward(self,x):\n","        return self.model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOfRqQ4Kt7MF","colab_type":"text"},"source":["## Train network"]},{"cell_type":"code","metadata":{"id":"Rw0dMKb-t_FJ","colab_type":"code","outputId":"b3a42896-235d-4d6b-bbbb-ac735150f74c","executionInfo":{"status":"error","timestamp":1564765317669,"user_tz":-60,"elapsed":546,"user":{"displayName":"Laurence Jackson","photoUrl":"https://lh4.googleusercontent.com/-7DuU4tbtAgI/AAAAAAAAAAI/AAAAAAAABA0/VkmK1bbpYbQ/s64/photo.jpg","userId":"10906345623450179926"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# store the training data as tensors\n","trainTensor = torch.from_numpy(trainImages[:,None])\n","segTensor = torch.from_numpy(trainSegs[:,None].astype(np.float32))\n","\n","# create network object\n","net = SegNet()\n","\n","# choose a device and  (remember to set Google Colab environment runtime to use GPU)\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# move the net and tensors to device memory\n","net = net.to(device)\n","trainTensor = trainTensor.to(device)\n","segTensor = segTensor.to(device)\n","\n","# define optimizer and loss function\n","opt=torch.optim.Adam(net.parameters(),0.008)\n","loss=DiceLoss()\n","\n","trainSteps = 5000\n","losses = []\n","\n","# run through training steps\n","for t in range(1,trainSteps+1):\n","    opt.zero_grad()\n","    pred = net(trainTensor)\n","    if t == 1:\n","      print('pred shape: ' + str(pred.size()))\n","      print('segTensor shape: ' + str(segTensor.size()))\n","    lossval = loss(pred,segTensor)\n","    lossval.backward()\n","    opt.step()\n","        \n","    losses.append(lossval.item())\n","    if t%(trainSteps//20) == 0:\n","        print(t,lossval.item())    \n","\n","# result\n","sample = np.random.randint(0, pred.shape[0]-1 )  # choose random sample to visualise segmentation the network predicted for it\n","print('Showing results from random sample: %d' % sample)\n","pred.shape\n","predSample=pred[sample,0].cpu().data.numpy()\n","fig,ax=plt.subplots(1,5,figsize=(20,5))\n","ax[0].set_title('Loss')\n","ax[0].semilogy(losses)\n","ax[1].set_title('Sample Image')\n","ax[1].imshow(trainImages[10])\n","ax[2].set_title('Sample Ground Truth')\n","ax[2].imshow(trainSegs[10])\n","ax[3].set_title('Sample Logits')\n","ax[3].imshow(predSample)\n","ax[4].set_title('Sample Predicted Segmentation')\n","ax[4].imshow(predSample>0.5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["pred shape: torch.Size([368, 1, 64, 64])\n","segTensor shape: torch.Size([368, 1, 64, 64])\n"],"name":"stdout"}]}]}