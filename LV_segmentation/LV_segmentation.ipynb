{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LV_segmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"},"widgets":{"state":{},"version":"1.1.2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eZe8vekln9j6"},"source":["# Neural network for segmenting LV of heart\n","\n","## Introduction\n","This work was performed as part of the MRAI workshop (MIDL 2019 satellite meeting) with exercises designed by Esther Puyol (https://github.com/estherpuyol/MRAI_workshop).\n","\n","### Objective\n","Train a simple neural network to automatically segment the Left ventricle from 2D short axis cardiac MR images."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MQirRpaep-kM"},"source":["## Import modules\n","The network is built using functions and classes from the [pytorch library](https://pytorch.org/docs/stable/index.html) "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"og-H1NZBqaFE","colab":{}},"source":["import os\n","import numpy as np\n","import pylab as plt#\n","import tensorflow as tf\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn.model_selection import StratifiedShuffleSplit"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P-2sznKCpSGC"},"source":["## Download dataset\n","The data for this study is from the [Sunnybrook Cardiac Data](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/)\n","\n","A preprocessed subset of this data is used, where the data is filtered to contain only left ventricle myocardium segmentations and reduced in XY dimensions."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1565686067007,"user_tz":-60,"elapsed":4341,"user":{"displayName":"Laurence Jackson","photoUrl":"https://lh4.googleusercontent.com/-7DuU4tbtAgI/AAAAAAAAAAI/AAAAAAAABA0/VkmK1bbpYbQ/s64/photo.jpg","userId":"10906345623450179926"}},"id":"-B0W1zJKpPdk","outputId":"035b2e17-8b21-4bde-d8c1-b3eb18ae8833","colab":{"base_uri":"https://localhost:8080/","height":311}},"source":["![ -f scd_lvsegs.npz ] || wget https://github.com/estherpuyol/MRAI_workshop/raw/master/scd_lvsegs.npz\n","\n","data = np.load('scd_lvsegs.npz') # load all the data from the archive\n","\n","images = data['images'] # images in BHW array order : .shape (420, 64, 64)]\n","segs = data['segs'] # segmentations in BHW array order : .shape (420, 64, 64)\n","caseIndices = data['caseIndices'] # the indices in `images` for each case : .shape (45, 2)\n","\n","images = images.astype(np.float32)/images.max() # normalize images"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2019-08-13 08:47:44--  https://github.com/estherpuyol/MRAI_workshop/raw/master/scd_lvsegs.npz\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/estherpuyol/MRAI_workshop/master/scd_lvsegs.npz [following]\n","--2019-08-13 08:47:44--  https://raw.githubusercontent.com/estherpuyol/MRAI_workshop/master/scd_lvsegs.npz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2133403 (2.0M) [application/octet-stream]\n","Saving to: ‘scd_lvsegs.npz’\n","\n","\rscd_lvsegs.npz        0%[                    ]       0  --.-KB/s               \rscd_lvsegs.npz      100%[===================>]   2.03M  --.-KB/s    in 0.04s   \n","\n","2019-08-13 08:47:45 (48.7 MB/s) - ‘scd_lvsegs.npz’ saved [2133403/2133403]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"A2mh117Tqibl"},"source":["## Split training and test data\n","This code block splits the data set into training and test data where the variable n_training determines the number of test cases.  "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0jQ8Ti5ZspKA","colab":{}},"source":["n_training = 6\n","\n","testIndex = caseIndices[-n_training,0] # keep the last n_training cases for testing\n","\n","# divide the images, segmentations, and categories into train/test sets\n","trainImages,trainSegs = images[:testIndex],segs[:testIndex]\n","testImages,testSegs = images[testIndex:],segs[testIndex:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q1uDuNzItFQx"},"source":["## Define segmentation network\n","Here two classes are defined: \n","\n","The first describes the loss function ```DiceLoss``` which will provide a measure of overlap between ground truth segmentations and the network outputs. \n","\n","The second class ```SegNet``` is our artifical neural network that inherits methods from the base NN class torch.nn.Module. \n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yoqHiPFytdg9","colab":{}},"source":["class DiceLoss(tf.keras.losses.Loss):\n","    '''This defines the binary dice loss function used to assess segmentation overlap.'''\n","    def call(self, y_pred, y_true, axis=(1, 2, 3), smooth=1e-5):\n","        y_pred = tf.math.sigmoid(y_pred)\n","        y_true = tf.math.sigmoid(y_true)\n","        inse = tf.reduce_sum(y_pred * y_true, axis=axis)\n","        l = tf.reduce_sum(y_pred, axis=axis)\n","        r = tf.reduce_sum(y_true, axis=axis)\n","\n","        dice = (2. * inse + smooth) / (l + r + smooth)\n","        ##\n","        dice = tf.reduce_mean(dice, name='dice_coe')\n","        return dice \n","\n","\n","\"\"\"\n","class unet_block(tf.keras.Model):\n","\n","    def __init__(self, Cin, Cout, subblock):\n","        super().__init__()\n","        self._encode = tf.keras.layers.Conv2D(Cout, (3,3), strides=(1,1), padding='valid', data_format='channels_first')\n","        self._encode_norm = tf.keras.layers.BatchNormalization(axis=1)\n","        self._encode_dropout = tf.keras.layers.Dropout(rate=0.2)\n","        self._encode_activation = tf.keras.layers.Activation(tf.nn.leaky_relu)\n","\n","        self._subblock = subblock\n","\n","        self._decode = tf.keras.layers.Conv2DTranspose(Cin, (3,3), strides=(1,1), padding='valid', data_format='channels_first')\n","        self._decode_norm = tf.keras.layers.BatchNormalization(axis=1)\n","        self._decode_dropout = tf.keras.layers.Dropout(rate=0.2)\n","        self._decode_activation = tf.keras.layers.Activation(tf.nn.leaky_relu)\n","\n","    def call(self, tensor_in):\n","#        Forward pass - encode block -> subblocks -> decode block\n","        enc = self._encode(tensor_in)\n","        enc = self._encode_norm(enc)\n","        #if training:\n","        enc = self._encode_dropout(enc)\n","        enc = self._encode_activation(enc)\n","\n","        sub = self._subblock(enc)\n","        sub = tf.concat([enc,sub], axis=1)\n","\n","        dec = self._decode(sub)\n","        dec = self._decode_norm(dec)\n","        #if training:\n","        dec = self._decode_dropout(dec)\n","        dec = self._decode_activation(dec)\n","\n","        return dec\n","\n","\n","class Unet(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        # bottom subblock\n","        net = tf.keras.Sequential()\n","        net.add(tf.keras.layers.Conv2D(64, (3,3), strides=2, padding='same', data_format='channels_first'))\n","        net.add(tf.keras.layers.BatchNormalization(axis=1))\n","        net.add(tf.keras.layers.PReLU())\n","\n","        # build the unet structure from the bottom up\n","        net=unet_block(32,64,net)\n","        net=unet_block(16,32,net)\n","        net=unet_block(8,16,net)\n","        net=unet_block(4,8,net)\n","\n","        # final top-level structure omits dropout and applies sigmoid to the output\n","        self.model = tf.keras.Sequential()\n","        self.model.add(tf.keras.layers.Conv2D(4, (3,3), strides=1, padding='same', data_format='channels_first'))\n","        self.model.add(tf.keras.layers.BatchNormalization(axis=1))\n","        self.model.add(tf.keras.layers.PReLU())\n","        self.model.add(net)\n","        self.model.add(tf.keras.layers.Conv2DTranspose(1, (3,3), strides=1, padding='same', data_format='channels_first'))\n","\n","    def call(self, x):\n","        return self.model(x)\n","\n","\"\"\"\n","\n","class Unet(tf.keras.Model):\n","    \"\"\"tf unet based on design https://keunwoochoi.wordpress.com/2017/10/11/u-net-on-keras-2-0/\"\"\"\n","    def __init__(self, conv_channels=[1], kernels=[5], training=True):\n","        super().__init__()\n","\n","        self._conv_channels = conv_channels\n","        self._kernels = kernels\n","\n","        # check kernel/substack size are equal and make them equal if only a single kernel size is used\n","        if (len(conv_channels) is not len(kernels)):\n","            if len(kernels) is 1:\n","                self._kernels = [item for item in self._kernels for i in range(len(self._conv_channels))]\n","            else:\n","                raise AssertionError('conv_channels and kernel lists must have equal length')\n","\n","        print(self._conv_channels)\n","        print(self._kernels)\n","\n","        self._encoder = []\n","\n","        # first bit define input\n","        input_tensor = tf.keras.Input(shape=(1, 64, 64))\n","        self._enc = input_tensor\n","\n","        # encode module\n","        for n, C_out in enumerate(self._conv_channels):\n","            print('%d : %d' % (n, C_out))\n","            self._enc = tf.keras.layers.Conv2D(C_out, self._kernels[n], strides=2, padding='same', data_format='channels_first')(self._enc)\n","            self._enc = tf.keras.layers.BatchNormalization(axis=1)(self._enc)\n","            self._enc = tf.keras.layers.PReLU()(self._enc)\n","            self._encoder.append(self._enc)\n","        \n","        # reverse channel list\n","        self._conv_channels = self._conv_channels[::-1]\n","        print(self._encoder)\n","\n","        # decode module\n","        self._dec = self._enc\n","        for n, C_in in enumerate(self._conv_channels):\n","            print('%d : %d' % (n, C_in))\n","            idx_rev = len(self._conv_channels) - n - 1\n","            print(idx_rev)\n","\n","            self._dec = tf.keras.layers.Conv2DTranspose(C_in, self._kernels[n], strides=2, padding='same', data_format='channels_first')(self._enc)\n","            self._dec = tf.keras.layers.BatchNormalization(axis=1)(self._dec)\n","            self._dec = tf.keras.layers.PReLU()(self._dec)\n","            self._dec = tf.concat([self._dec, self._encoder[idx_rev]], axis=1)\n","        \n","        self.model = tf.keras.Model(inputs=[input_tensor],outputs=[output_tensor])\n","\n","    def call(self, x):\n","        return self.model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YOfRqQ4Kt7MF"},"source":["## Train network"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1565719323040,"user_tz":-60,"elapsed":1206,"user":{"displayName":"Laurence Jackson","photoUrl":"https://lh4.googleusercontent.com/-7DuU4tbtAgI/AAAAAAAAAAI/AAAAAAAABA0/VkmK1bbpYbQ/s64/photo.jpg","userId":"10906345623450179926"}},"id":"Rw0dMKb-t_FJ","outputId":"0aa2c42b-581e-4f73-f6d9-b9861c12c09e","colab":{"base_uri":"https://localhost:8080/","height":639}},"source":["# store the training data as tensors\n","trainTensor = tf.convert_to_tensor(trainImages[:,None].astype(np.float32))\n","segTensor = tf.convert_to_tensor(trainSegs[:,None].astype(np.float32))\n","\n","# create network object\n","channels= [2, 4, 8, 16]\n","net = Unet(channels)\n","\n","# choose a device and  (remember to set Google Colab environment runtime to use GPU)\n","tf.device(\"/device:GPU:0\")\n","\n","# define optimizer and loss function\n","opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n","\n","#net.compile(opt,loss=DiceLoss(), metrics=['accuracy'])\n","\n","net.compile(opt,loss=tf.keras.losses.BinaryCrossentropy())\n","\n","net.fit(trainTensor, segTensor, batch_size=32, epochs=5, steps_per_epoch=200)\n","\n","net.summary()\n","\n","# result\n","#sample = np.random.randint(0, trainTensor.shape[0]-1 )  # choose random sample to visualise segmentation the network predicted for it\n","sample=10\n","print('Showing results from random sample: %d' % sample)\n","\n","pred = net.predict(trainTensor, steps=1)\n","pred.shape\n","\n","predSample=np.squeeze(pred[sample,:])\n","\n","fig,ax=plt.subplots(1,5,figsize=(20,5))\n","#ax[0].set_title('Loss')\n","#ax[0].semilogy(losses)\n","ax[1].set_title('Sample Image')\n","ax[1].imshow(trainImages[sample])\n","ax[2].set_title('Sample Ground Truth')\n","ax[2].imshow(trainSegs[sample])\n","ax[3].set_title('Sample Logits')\n","ax[3].imshow(predSample)\n","ax[4].set_title('Sample Predicted Segmentation')\n","ax[4].imshow(predSample>0.5)"],"execution_count":200,"outputs":[{"output_type":"stream","text":["ListWrapper([2, 4, 8, 16])\n","ListWrapper([5, 5, 5, 5])\n","0 : 2\n","1 : 4\n","2 : 8\n","3 : 16\n","ListWrapper([<tf.Tensor 'p_re_lu_315/add:0' shape=(?, 2, 32, 32) dtype=float32>, <tf.Tensor 'p_re_lu_316/add:0' shape=(?, 4, 16, 16) dtype=float32>, <tf.Tensor 'p_re_lu_317/add:0' shape=(?, 8, 8, 8) dtype=float32>, <tf.Tensor 'p_re_lu_318/add:0' shape=(?, 16, 4, 4) dtype=float32>])\n","0 : 16\n","3\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 8 and 4. Shapes are [8,8] and [4,4]. for 'concat_70' (op: 'ConcatV2') with input shapes: [?,16,8,8], [?,16,4,4], [] and with computed input tensors: input[2] = <1>.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-200-e83e39458e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create network object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# choose a device and  (remember to set Google Colab environment runtime to use GPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-199-2190b286dd08>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, conv_channels, kernels, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_rev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1297\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1298\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1256\u001b[0;31m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   1257\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 8 and 4. Shapes are [8,8] and [4,4]. for 'concat_70' (op: 'ConcatV2') with input shapes: [?,16,8,8], [?,16,4,4], [] and with computed input tensors: input[2] = <1>."]}]}]}